{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d9bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "306c2e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 382 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                rescale = 1./255,\n",
    "                shear_range = 0.2,\n",
    "                zoom_range = 0.2,\n",
    "                rotation_range= 45,\n",
    "                width_shift_range= 0.2,\n",
    "                height_shift_range= 0.2,\n",
    "                fill_mode = 'nearest',\n",
    "                horizontal_flip = True)\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "            'Train',\n",
    "            target_size = (180,180),\n",
    "            batch_size = 32,\n",
    "            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4348141a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('Test',\n",
    "                                           target_size = (180,180),\n",
    "                                           batch_size = 32,\n",
    "                                           class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf505450",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "170695bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=16,kernel_size=3,activation='relu',input_shape=[180,180,3]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d504bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87362c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d67fbee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c53eeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())\n",
    "# cnn.add(tf.keras.layers.Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e01f637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=512,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "319123a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=4,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21a7b56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ac45bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 178, 178, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 89, 89, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 87, 87, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 43, 43, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 41, 41, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 20, 20, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 18, 18, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 9, 9, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 10368)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               5308928   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,408,420\n",
      "Trainable params: 5,408,420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84b9da96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 11s 774ms/step - loss: 0.5984 - accuracy: 0.2775 - val_loss: 0.5766 - val_accuracy: 0.2500\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 8s 681ms/step - loss: 0.5460 - accuracy: 0.3586 - val_loss: 0.5076 - val_accuracy: 0.4333\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 10s 792ms/step - loss: 0.4887 - accuracy: 0.5314 - val_loss: 0.4429 - val_accuracy: 0.6083\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 9s 736ms/step - loss: 0.4545 - accuracy: 0.5497 - val_loss: 0.4673 - val_accuracy: 0.5083\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 8s 632ms/step - loss: 0.4217 - accuracy: 0.5969 - val_loss: 0.4433 - val_accuracy: 0.5917\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 8s 690ms/step - loss: 0.4006 - accuracy: 0.6126 - val_loss: 0.4500 - val_accuracy: 0.6000\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 8s 689ms/step - loss: 0.3706 - accuracy: 0.6649 - val_loss: 0.4364 - val_accuracy: 0.6250\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 9s 735ms/step - loss: 0.3848 - accuracy: 0.6387 - val_loss: 0.4078 - val_accuracy: 0.5917\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 8s 690ms/step - loss: 0.3497 - accuracy: 0.7016 - val_loss: 0.4737 - val_accuracy: 0.5750\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 9s 731ms/step - loss: 0.3474 - accuracy: 0.6963 - val_loss: 0.4256 - val_accuracy: 0.6083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25eac37b390>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x=train_set,validation_data=test_set,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f43c352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Blotch_Apple': 0, 'Normal_Apple': 1, 'Rot_Apple': 2, 'Scab_Apple': 3}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2615a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 189ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import load_img,img_to_array\n",
    "test_image = load_img('test_cases/rbl_test_rot2.jpeg', target_size = (180, 180))\n",
    "test_image = img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image,axis=0)\n",
    "result = cnn.predict(test_image/255.0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fabd10c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46288845\n",
      "Normal Apple\n"
     ]
    }
   ],
   "source": [
    "max_val = 0\n",
    "img_type = 0;\n",
    "for i in range(0,4):\n",
    "    if(max_val < result[i]):\n",
    "        max_val = result[i]\n",
    "        img_type = i\n",
    "print(max_val)\n",
    "if(img_type == 0):\n",
    "    print(\"Blotch_Apple\")\n",
    "if(img_type == 1):\n",
    "    print(\"Normal Apple\")\n",
    "if(img_type == 2):\n",
    "    print(\"Rot_Apple\")\n",
    "if(img_type == 3):\n",
    "    print(\"Scab Apple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b91433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Blotch_Apple', 'Normal_Apple', 'Rot_Apple', 'Scab_Apple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c61fec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img):\n",
    "    img_4d=img.reshape(-1,180,180,3)\n",
    "    test_image = img_to_array(img)\n",
    "    test_image = np.expand_dims(test_image,axis=0)\n",
    "    prediction=cnn.predict(test_image)[0]\n",
    "    return {class_names[i]: float(prediction[i]) for i in range(4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3d6e9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.Interface(fn=predict_image, inputs=gr.Image(shape=(180,180)), outputs=gr.Label(num_top_classes=4),\n",
    "             interpretation='default').launch(debug=True )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
